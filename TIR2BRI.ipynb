{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Setup Environment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Sys varibles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "if 'google.colab' in sys.modules:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive/')\n",
        "    !cp -r \"/content/drive/MyDrive/Training/\" \"/content/Training\"\n",
        "    !cd \"/content/Training\"\n",
        "    sys.path.append(\"/content/Training\")\n",
        "#For disable GPU\n",
        "#import os\n",
        "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Load Libs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PknTm2yZ_QED"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import os\n",
        "from skimage import io\n",
        "from sklearn.model_selection import train_test_split\n",
        "from TRI2BRI import tIR2bri\n",
        "from util import imageToInput, inputToImage\n",
        "from training_GAN import train, train_d, test, Discriminator, adap_train, adap_train_d\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "from statistics import mean\n",
        "import numpy as np\n",
        "import math"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Init random seed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "SEED = 14285\n",
        "\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Load Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yzWbPKiMbHb4"
      },
      "outputs": [],
      "source": [
        "tIR_model = tIR2bri()\n",
        "d_model = Discriminator()\n",
        "tIR_model.load_state_dict(torch.load(\"tIR2BRI_e134_0.0001_1513_last.ckpt\"))\n",
        "if torch.cuda.is_available():\n",
        "    tIR_model = tIR_model.cuda()\n",
        "    d_model = d_model.cuda()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Loader Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bBnNVOanJeW3"
      },
      "outputs": [],
      "source": [
        "def get_file_list(input_dir, result_dir):\n",
        "    \"\"\"Get file list for model training\n",
        "\n",
        "    Args:\n",
        "        input_dir (str): Input file directory (X)\n",
        "        result_dir (str): Result file directory (Y)\n",
        "\n",
        "    Returns:\n",
        "        List: List of file pair contains (X_path, Y_path)\n",
        "    \"\"\"\n",
        "    result = []\n",
        "    for filename in os.listdir(input_dir):\n",
        "        fIR = os.path.join(input_dir, filename)\n",
        "        fGRAY = os.path.join(result_dir, filename)\n",
        "        if os.path.isfile(fIR) and os.path.isfile(fGRAY):\n",
        "            result.append((fIR,fGRAY))\n",
        "    return result\n",
        "\n",
        "def data_generator(file_list,shuffle=True):\n",
        "    \"\"\"Generate Data from file list.\n",
        "\n",
        "    Args:\n",
        "        file_list ([(str,str)]): contains list of file paths for training data in (X,Y) format.\n",
        "\n",
        "    Yields:\n",
        "        (ndarray, ndarray): Two image tuple of (X, Y)\n",
        "    \"\"\"\n",
        "    if shuffle:\n",
        "        file_list = file_list[:]\n",
        "        random.shuffle(file_list)\n",
        "    for fIR, fGRAY in file_list:\n",
        "        x = imageToInput(io.imread(fIR))\n",
        "        y = imageToInput(io.imread(fGRAY))\n",
        "        yield x, y\n",
        "\n",
        "def data_generator_inf(file_list,shuffle=True):\n",
        "    \"\"\"Random sample data from file list.\n",
        "\n",
        "    Args:\n",
        "        file_list ([(str,str)]): contains list of file paths for training data in (X,Y) format.\n",
        "\n",
        "    Yields:\n",
        "        (ndarray, ndarray): Two image tuple of (X, Y)\n",
        "    \"\"\"\n",
        "    while True:\n",
        "        fIR, fGRAY = random.choice(file_list)\n",
        "        x = imageToInput(io.imread(fIR))\n",
        "        y = imageToInput(io.imread(fGRAY))\n",
        "        yield x, y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Training Prcess"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Set Training Varibles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ih5T8jN3Lb6y"
      },
      "outputs": [],
      "source": [
        "x_dir = \"./IR-256\"\n",
        "y_dir = \"./GRAY-256\"\n",
        "if 'google.colab' in sys.modules:\n",
        "    x_dir = \"/content/Training/IR-256\"\n",
        "    y_dir = \"/content/Training/GRAY-256\"\n",
        "\n",
        "\n",
        "file_list = get_file_list(x_dir, y_dir)\n",
        "#train_file, test_file = train_test_split(\n",
        "#    file_list, test_size=0.2, random_state=10)\n",
        "cut = math.floor(len(file_list)*0.8)\n",
        "train_file, test_file = (file_list[:cut],file_list[cut:])\n",
        "n_epochs = 120\n",
        "all_loss_train = []\n",
        "all_loss_test = []\n",
        "all_epoch = []\n",
        "all_d_loss = []\n",
        "epoch = 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Training Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "d_threshold = 0.05\n",
        "g_threshold = 0.005\n",
        "max_d_iter = 100\n",
        "moving_avg_size = 10\n",
        "tIR_model.train()\n",
        "d_model.train()\n",
        "# Write as while loop, so we can resume interrupts\n",
        "while epoch < n_epochs:\n",
        "    train_d_generator = adap_train_d(\n",
        "        tIR_model, d_model, data_generator_inf(train_file), d_learning_rate=0.0005)\n",
        "    train_generator = adap_train(\n",
        "        tIR_model, d_model, data_generator(train_file), learning_rate=0.0001)\n",
        "    loss_d = 0\n",
        "\n",
        "    g_empty = False\n",
        "    while not g_empty:\n",
        "        sloss_d_list = [d_threshold]\n",
        "        g_sloss_d_list = [g_threshold]\n",
        "        # Train Discriminator\n",
        "        count_d_iter = 0\n",
        "        for sloss_d, loss_d in train_d_generator:\n",
        "            d_empty = False\n",
        "            sloss_d_list.append(sloss_d)\n",
        "            if len(sloss_d_list) > moving_avg_size:\n",
        "                sloss_d_list.pop(0)\n",
        "            count_d_iter += 1\n",
        "            if mean(sloss_d_list) < d_threshold or count_d_iter > max_d_iter:\n",
        "                break\n",
        "        # Train generator\n",
        "        g_empty = True\n",
        "        for g_sloss_d, current_loss_train in train_generator:\n",
        "            g_empty = False\n",
        "            g_sloss_d_list.append(g_sloss_d)\n",
        "            if len(g_sloss_d_list) > moving_avg_size:\n",
        "                g_sloss_d_list.pop(0)\n",
        "            if mean(g_sloss_d_list) < g_threshold:\n",
        "                break\n",
        "            g_empty = True\n",
        "\n",
        "    current_loss_test = test(tIR_model, d_model, data_generator(test_file))\n",
        "    all_loss_train.append(current_loss_train)\n",
        "    all_loss_test.append(current_loss_test)\n",
        "    all_epoch.append(epoch)\n",
        "    all_d_loss.append(loss_d)\n",
        "    epoch += 1\n",
        "    print(\"\\rEpoch=\", epoch, \" Loss=\", format(current_loss_train, '.5g'),\n",
        "          \",\", format(current_loss_test, '.5g'), \" D_LOSS=\", format(loss_d, '.5g'), sep=\"\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Regular Traing without adaptive GAN learning process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Write as while loop, so we can resume interrupts\n",
        "# while epoch < n_epochs:\n",
        "#     loss_d = train_d(tIR_model, d_model, data_generator(train_file), d_learning_rate=0.005)\n",
        "#     current_loss_train = train(\n",
        "#         tIR_model, d_model, data_generator(train_file), learning_rate=0.001)\n",
        "#     current_loss_test = test(tIR_model, d_model, data_generator(test_file))\n",
        "#     all_loss_train.append(current_loss_train)\n",
        "#     all_loss_test.append(current_loss_test)\n",
        "#     all_epoch.append(epoch)\n",
        "#     all_d_loss.append(loss_d)\n",
        "#     epoch += 1\n",
        "#     print(\"\\rEpoch=\", epoch, \" Loss=\", format(current_loss_train, '.5g'),\n",
        "#           \",\", format(current_loss_test, '.5g'), \" D_LOSS=\", format(loss_d, '.5g'), sep=\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Save Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.save(tIR_model.state_dict(), \"tIR2BRI_e134_0.0001_1513_last.ckpt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Evaluate Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Show training stat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.plot(all_epoch, all_loss_test, label = \"Test Loss\")\n",
        "plt.plot(all_epoch, all_loss_train, label = \"Train Loss\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.plot(all_epoch, all_d_loss, label = \"D Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Load Data for testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data = data_generator(test_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tIR_model.eval()\n",
        "x, y = next(data)\n",
        "torch.cuda.empty_cache() "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Plot data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if torch.cuda.is_available():\n",
        "    x = x.cuda()\n",
        "\n",
        "output = x\n",
        "output = inputToImage(x.cpu().detach())\n",
        "io.imshow(output)\n",
        "plt.title(\"Thermal IR Image\")\n",
        "plt.show()\n",
        "io.imsave(\"./output/Thermal_IR.png\", output)\n",
        "\n",
        "output = tIR_model(x)\n",
        "output = inputToImage(output.cpu().detach())\n",
        "io.imshow(output)\n",
        "plt.title(\"Generated Image\")\n",
        "plt.show()\n",
        "io.imsave(\"./output/Generated.png\", output)\n",
        "\n",
        "output = y\n",
        "output = inputToImage(y.cpu().detach())\n",
        "io.imshow(output)\n",
        "plt.title(\"Target Image\")\n",
        "plt.show()\n",
        "io.imsave(\"./output/Target.png\", output)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "interpreter": {
      "hash": "bc5ef86e6eb5fe0e1640be2e622c08f7359d21492195ea8a790d9b18f5cf0377"
    },
    "kernelspec": {
      "display_name": "Python 3.9.1 64-bit (system)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
